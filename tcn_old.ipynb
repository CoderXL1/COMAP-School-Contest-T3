{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T08:07:06.183636Z",
     "start_time": "2026-01-19T08:07:06.167887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ],
   "id": "2b7c0427fc3f3878",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T07:56:46.050806Z",
     "start_time": "2026-01-19T07:56:46.001117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATA_DIR = '/Users/aplle/Code/MathModeling/SC/dataset1'\n",
    "MODEL_DIR = '/Users/aplle/Code/MathModeling/SC/models'"
   ],
   "id": "e9919ae01e04034f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T08:02:11.380392Z",
     "start_time": "2026-01-19T08:02:09.394562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv(f\"{DATA_DIR}/train.csv\")\n",
    "eval_df = pd.read_csv(f\"{DATA_DIR}/eval.csv\")\n",
    "test_df = pd.read_csv(f\"{DATA_DIR}/test.csv\")\n",
    "\n",
    "POWER_DIVISOR = 1000.0\n",
    "YEAR_MIN = 2016\n",
    "YEAR_MAX = 2018\n",
    "\n",
    "def is_leap(yr:int):\n",
    "    if yr % 400 == 0:\n",
    "        return True\n",
    "    elif yr % 100 == 0:\n",
    "        return False\n",
    "    elif yr % 4 == 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_ndays(yr:int):\n",
    "    return 366 if is_leap(yr) else 365\n",
    "\n",
    "def preprocess_df(df):\n",
    "    df.dropna(subset=['Power (kW)'], inplace=True)\n",
    "    df['Power (kW)'] = df['Power (kW)'] / POWER_DIVISOR\n",
    "    df.rename(columns={'Power (kW)': 'Power'}, inplace=True)\n",
    "\n",
    "    df['Days_from_NYD'] = df['Days_from_NYD'] / df['Year'].apply(get_ndays)\n",
    "\n",
    "    df['Year'] = df['Year'] - YEAR_MIN\n",
    "    df['Year'] = df['Year'] / (YEAR_MAX - YEAR_MIN)\n",
    "\n",
    "    df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S')\n",
    "    df['Time'] = df['Time'].dt.hour * 60 + df['Time'].dt.minute\n",
    "    df['Time'] = df['Time'] / (24 * 60)\n",
    "\n",
    "    df.drop(['Day', 'Span'], axis=1, inplace=True)\n",
    "\n",
    "    df['Month'] = df['Month'] / 12.0\n",
    "\n",
    "    df['Weekday'] = df['Weekday'] / 6.0\n",
    "\n",
    "    df['Region'] = df['Region'].map({\n",
    "        'Commercial': 0,\n",
    "        'Office': 1,\n",
    "        'Public': 2,\n",
    "        'Residential': 3\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = preprocess_df(train_df)\n",
    "_train_columns = train_df.columns.copy()\n",
    "\n",
    "eval_df = preprocess_df(eval_df)\n",
    "eval_df = eval_df.reindex(columns=_train_columns, fill_value=0)\n",
    "\n",
    "test_df = preprocess_df(test_df)\n",
    "test_df = test_df.reindex(columns=_train_columns, fill_value=0)\n"
   ],
   "id": "b565d102fd26dcff",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T08:28:28.998781Z",
     "start_time": "2026-01-19T08:28:28.895381Z"
    }
   },
   "cell_type": "code",
   "source": "train_df",
   "id": "abeb3e174fb03bd8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Time    Power  Year     Month   Weekday  Region  Days_from_NYD\n",
       "0       0.000000  0.39240   0.0  0.083333  0.666667       3       0.000000\n",
       "1       0.003472  0.38900   0.0  0.083333  0.666667       3       0.000000\n",
       "2       0.006944  0.36740   0.0  0.083333  0.666667       3       0.000000\n",
       "3       0.010417  0.37117   0.0  0.083333  0.666667       3       0.000000\n",
       "4       0.013889  0.35280   0.0  0.083333  0.666667       3       0.000000\n",
       "...          ...      ...   ...       ...       ...     ...            ...\n",
       "826898  0.986111  0.16480   1.0  0.166667  0.333333       2       0.158904\n",
       "826899  0.989583  0.14880   1.0  0.166667  0.333333       2       0.158904\n",
       "826900  0.993056  0.15440   1.0  0.166667  0.333333       2       0.158904\n",
       "826901  0.996528  0.15240   1.0  0.166667  0.333333       2       0.158904\n",
       "826902  0.000000  0.13680   1.0  0.166667  0.333333       2       0.161644\n",
       "\n",
       "[811771 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Power</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Region</th>\n",
       "      <th>Days_from_NYD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.39240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.38900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.36740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.37117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.35280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826898</th>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.16480</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>0.158904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826899</th>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.14880</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>0.158904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826900</th>\n",
       "      <td>0.993056</td>\n",
       "      <td>0.15440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>0.158904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826901</th>\n",
       "      <td>0.996528</td>\n",
       "      <td>0.15240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>0.158904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826902</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.13680</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>0.161644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>811771 rows Ã— 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-19T07:57:39.350928Z",
     "start_time": "2026-01-19T07:57:39.320478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PowerTCNDataset(data.Dataset):\n",
    "    def __init__(self, df, hist_len, time_cols):\n",
    "        self.hist_len = hist_len\n",
    "        self.time_cols = time_cols\n",
    "\n",
    "        self.x_hist = []\n",
    "        self.x_time = []\n",
    "        self.x_loc = []\n",
    "        self.y = []\n",
    "\n",
    "        for loc, g in df.groupby(\"Region\"):\n",
    "            g:pd.DataFrame = g.reset_index(drop=True)\n",
    "\n",
    "            power = g[\"Power\"].to_numpy().astype(np.float32)\n",
    "            time_feat = g[time_cols].to_numpy().astype(np.float32)\n",
    "\n",
    "            for t in range(hist_len, len(g)):\n",
    "                self.x_hist.append(power[t - hist_len:t])  # X_hist\n",
    "                self.x_time.append(time_feat[t])           # X_time\n",
    "                self.x_loc.append(loc)                      # X_loc\n",
    "                self.y.append(power[t])                     # y\n",
    "\n",
    "        self.x_hist = torch.tensor(self.x_hist)\n",
    "        self.x_time = torch.tensor(self.x_time)\n",
    "        self.x_loc = torch.tensor(self.x_loc, dtype=torch.long)\n",
    "        self.y = torch.tensor(self.y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x_loc.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.x_hist[idx].unsqueeze(0),  # [1, k]\n",
    "            self.x_time[idx],             # [d_time]\n",
    "            self.x_loc[idx],\n",
    "            self.y[idx]\n",
    "        )"
   ],
   "id": "1e8563a1b0081a4b",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T08:03:39.963201Z",
     "start_time": "2026-01-19T08:03:38.730768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "HIST_LEN = 288\n",
    "TIME_COLS = [\n",
    "    \"Time\",\n",
    "    \"Year\",\n",
    "    \"Month\",\n",
    "    \"Weekday\",\n",
    "    \"Days_from_NYD\"\n",
    "]\n",
    "\n",
    "train_ds = PowerTCNDataset(train_df, HIST_LEN, TIME_COLS)\n",
    "eval_ds = PowerTCNDataset(eval_df, HIST_LEN, TIME_COLS)\n",
    "\n",
    "train_loader = data.DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "eval_loader = data.DataLoader(eval_ds, batch_size=64, shuffle=False)"
   ],
   "id": "bb626caf1a9857bc",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T08:05:17.633520Z",
     "start_time": "2026-01-19T08:05:17.605403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.nn.utils.parametrizations import weight_norm\n",
    "\n",
    "class TCNBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size, dilation, dropout):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) * dilation\n",
    "\n",
    "        self.conv1 = weight_norm(\n",
    "            nn.Conv1d(in_ch, out_ch, kernel_size,\n",
    "                      padding=padding, dilation=dilation)\n",
    "        )\n",
    "        self.conv2 = weight_norm(\n",
    "            nn.Conv1d(out_ch, out_ch, kernel_size,\n",
    "                      padding=padding, dilation=dilation)\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.downsample = (\n",
    "            nn.Conv1d(in_ch, out_ch, 1)\n",
    "            if in_ch != out_ch else None\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = out[..., :-self.conv1.padding[0]]  # causal crop\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = out[..., :-self.conv2.padding[0]]\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return out + res"
   ],
   "id": "b65c8480faf8bae5",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T08:05:20.319572Z",
     "start_time": "2026-01-19T08:05:20.286483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PowerTCN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hist_len,\n",
    "        time_dim,\n",
    "        num_locations=4,\n",
    "        loc_emb_dim=6,\n",
    "        channels=64,\n",
    "        layers=7,\n",
    "        kernel_size=3,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        blocks = []\n",
    "        in_ch = 1\n",
    "        for i in range(layers):\n",
    "            blocks.append(\n",
    "                TCNBlock(\n",
    "                    in_ch, channels,\n",
    "                    kernel_size,\n",
    "                    dilation=2 ** i,\n",
    "                    dropout=dropout\n",
    "                )\n",
    "            )\n",
    "            in_ch = channels\n",
    "\n",
    "        self.tcn = nn.Sequential(*blocks)\n",
    "        self.loc_emb = nn.Embedding(num_locations, loc_emb_dim)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(channels + time_dim + loc_emb_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_hist, x_time, x_loc):\n",
    "        \"\"\"\n",
    "        x_hist: [B, 1, k]\n",
    "        x_time: [B, d_time]\n",
    "        x_loc : [B]\n",
    "        \"\"\"\n",
    "        h = self.tcn(x_hist)          # [B, C, k]\n",
    "        h = h[:, :, -1]               # [B, C]\n",
    "\n",
    "        loc = self.loc_emb(x_loc)     # [B, loc_emb_dim]\n",
    "\n",
    "        z = torch.cat([h, x_time, loc], dim=1)\n",
    "        return self.mlp(z).squeeze(1)\n"
   ],
   "id": "4b3a70d9026d0457",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T08:05:21.973623Z",
     "start_time": "2026-01-19T08:05:21.908875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = PowerTCN(\n",
    "    hist_len=HIST_LEN,\n",
    "    time_dim=len(TIME_COLS)\n",
    ").to(device)\n"
   ],
   "id": "926c206943733a17",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T08:47:25.776486Z",
     "start_time": "2026-01-19T08:47:25.747996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_epoch(loader, opt, loss_fn, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.set_grad_enabled(train):\n",
    "        for x_hist, x_time, x_loc, y in loader:\n",
    "            x_hist = x_hist.to(device)\n",
    "            x_time = x_time.to(device)\n",
    "            x_loc  = x_loc.to(device)\n",
    "            y      = y.to(device)\n",
    "\n",
    "            pred = model(x_hist, x_time, x_loc)\n",
    "            l = loss_fn(pred, y)\n",
    "\n",
    "            if train:\n",
    "                opt.zero_grad()\n",
    "                l.backward()\n",
    "                opt.step()\n",
    "\n",
    "            total_loss += l.item() * len(y)\n",
    "\n",
    "    return total_loss / len(loader.dataset)\n"
   ],
   "id": "12dab7d81693497b",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T08:47:26.175869Z",
     "start_time": "2026-01-19T08:47:26.153166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train(model, train_loader, eval_loader, epochs=50, lr=1e-3, weight_decay=1e-4, checkpoint_path=\"best_tcn.pt\"):\n",
    "    best_eval = float(\"inf\")\n",
    "\n",
    "    opt = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.HuberLoss(delta=1.0)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_epoch(train_loader, opt, loss_fn, train=True)\n",
    "        eval_loss   = train_epoch(eval_loader, opt, loss_fn, train=False)\n",
    "\n",
    "        print(f\"Epoch {epoch:03d} | train {train_loss:.4f} | val {eval_loss:.4f}\")\n",
    "\n",
    "        if eval_loss < best_eval:\n",
    "            best_eval = eval_loss\n",
    "            if checkpoint_path is not None:\n",
    "                try:\n",
    "                    torch.save(model.state_dict(), os.path.join(MODEL_DIR, checkpoint_path))\n",
    "                except Exception:\n",
    "                    pass\n"
   ],
   "id": "f8904ccfdb85473e",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T08:54:18.418453Z",
     "start_time": "2026-01-19T08:47:27.092757Z"
    }
   },
   "cell_type": "code",
   "source": "train(model, train_loader, eval_loader)",
   "id": "54f166bc1c721bb8",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[33], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_loader\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[32], line 10\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, train_loader, eval_loader, epochs, lr, weight_decay, checkpoint_path)\u001B[0m\n\u001B[1;32m      7\u001B[0m loss_fn \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mHuberLoss(delta\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.0\u001B[39m)\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m---> 10\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     eval_loss   \u001B[38;5;241m=\u001B[39m train_epoch(eval_loader, opt, loss_fn, train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m03d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | train \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | val \u001B[39m\u001B[38;5;132;01m{\u001B[39;00meval_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[31], line 17\u001B[0m, in \u001B[0;36mtrain_epoch\u001B[0;34m(loader, opt, loss_fn, train)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m train:\n\u001B[1;32m     16\u001B[0m     opt\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 17\u001B[0m     \u001B[43ml\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m     opt\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     20\u001B[0m total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m l\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(y)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.8.20/lib/python3.8/site-packages/torch/_tensor.py:522\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    513\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    514\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    515\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    520\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    521\u001B[0m     )\n\u001B[0;32m--> 522\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.8.20/lib/python3.8/site-packages/torch/autograd/__init__.py:266\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    261\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 266\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7cf9b240dc83c05f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
